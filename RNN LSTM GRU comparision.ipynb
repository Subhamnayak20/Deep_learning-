{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf95cd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 12:50:24.331895: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-02 12:50:24.403361: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-02 12:51:42.898595: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8db1d53-12c5-42b0-ab84-38a5abc45fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step \n",
      "train data shape(25000, 200)\n",
      "test data shape(25000, 200)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "vocab_size = 10000\n",
    "max_len = 200\n",
    "\n",
    "(X_train,y_train) , (X_test,y_test) = imdb.load_data(num_words = vocab_size)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen = max_len , padding = \"post\")\n",
    "X_test = pad_sequences(X_test, maxlen = max_len , padding = \"post\")\n",
    "\n",
    "print(f\"train data shape{X_train.shape}\")\n",
    "print(f\"test data shape{X_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f9f75",
   "metadata": {},
   "source": [
    "## RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d5442af-de30-4453-8b78-7772a26045f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 130ms/step - accuracy: 0.5227 - loss: 0.6931 - val_accuracy: 0.5334 - val_loss: 0.6822\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 117ms/step - accuracy: 0.5818 - loss: 0.6537 - val_accuracy: 0.6152 - val_loss: 0.6349\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 116ms/step - accuracy: 0.6295 - loss: 0.6047 - val_accuracy: 0.5580 - val_loss: 0.6728\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 110ms/step - accuracy: 0.6500 - loss: 0.5845 - val_accuracy: 0.5796 - val_loss: 0.6569\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 110ms/step - accuracy: 0.6635 - loss: 0.5276 - val_accuracy: 0.6026 - val_loss: 0.6646\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 33ms/step - accuracy: 0.6028 - loss: 0.6631\n",
      "test loss: 0.6631, Test accuracy: 0.6028\n"
     ]
    }
   ],
   "source": [
    "#model designing\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim = vocab_size, output_dim = 128),\n",
    "    SimpleRNN(128 , activation = \"tanh\" , return_sequences = False),\n",
    "    Dense(1,activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train,y_train, epochs = 5 , batch_size = 32, validation_split = 0.2)\n",
    "loss, accuracy = model.evaluate(X_test,y_test)\n",
    "\n",
    "print(f\"test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45cb09b2-2adf-4a53-97ce-8b39d86bd5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n",
      "GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPUs:\",len( tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db7555-4305-4705-8dcc-e426acc74bd3",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b05fc9-9a14-49be-9026-2744853c454a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25a921-3177-46c5-a4a5-3ae3b4978bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b2cec-cc42-40a4-b3b8-0b99c672045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding , SimpleRNN, LSTM , Dense, GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8f9d1-d0bd-4f7d-ab4f-d7992abf0c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim = vocab_size,output_dim = 128),\n",
    "    LSTM(128, activation = \"tanh\", return_sequences = False),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "\n",
    "lstm_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "lstm_model.summary()\n",
    "\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs = 5, batch_size =32, validation_split = 0.2)\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test,y_test)\n",
    "\n",
    "print(f\"lstm Test Loss: {lstm_loss:.4f}, LSTM Test Accuracy: {lstm_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c261be-11cd-40d2-bbd1-0b1b3b130221",
   "metadata": {},
   "source": [
    "# GRU\n",
    "it have 2 gates(update and reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec9df323-385a-41aa-942d-9e82c8c06057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape(25000, 200)\n",
      "test data shape(25000, 200)\n",
      "WARNING:tensorflow:From C:\\Users\\nsubh\\anaconda3\\envs\\entire\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nsubh\\anaconda3\\envs\\entire\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         1280000   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1313025 (5.01 MB)\n",
      "Trainable params: 1313025 (5.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\nsubh\\anaconda3\\envs\\entire\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nsubh\\anaconda3\\envs\\entire\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "4000/4000 [==============================] - 401s 99ms/step - loss: 0.6987 - accuracy: 0.5095 - val_loss: 0.6876 - val_accuracy: 0.5286\n",
      "Epoch 2/5\n",
      "4000/4000 [==============================] - 416s 104ms/step - loss: 0.6628 - accuracy: 0.5748 - val_loss: 0.6810 - val_accuracy: 0.5492\n",
      "Epoch 3/5\n",
      "4000/4000 [==============================] - 402s 100ms/step - loss: 0.6230 - accuracy: 0.6091 - val_loss: 0.6862 - val_accuracy: 0.5478\n",
      "Epoch 4/5\n",
      "4000/4000 [==============================] - 380s 95ms/step - loss: 0.5931 - accuracy: 0.6309 - val_loss: 0.7257 - val_accuracy: 0.5600\n",
      "Epoch 5/5\n",
      "4000/4000 [==============================] - 372s 93ms/step - loss: 0.5705 - accuracy: 0.6592 - val_loss: 0.7255 - val_accuracy: 0.5776\n",
      "782/782 [==============================] - 32s 40ms/step - loss: 0.7300 - accuracy: 0.5681\n",
      "Rnn Test Loss: 0.7300, Test Accuracy: 0.5681\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 128)         1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1411713 (5.39 MB)\n",
      "Trainable params: 1411713 (5.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 225s 352ms/step - loss: 0.6225 - accuracy: 0.6444 - val_loss: 0.6857 - val_accuracy: 0.5674\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 221s 353ms/step - loss: 0.5395 - accuracy: 0.7150 - val_loss: 0.6362 - val_accuracy: 0.6336\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 239s 383ms/step - loss: 0.4520 - accuracy: 0.8023 - val_loss: 0.6267 - val_accuracy: 0.5622\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 217s 347ms/step - loss: 0.5343 - accuracy: 0.7054 - val_loss: 0.4842 - val_accuracy: 0.7996\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 217s 347ms/step - loss: 0.4388 - accuracy: 0.7926 - val_loss: 0.4186 - val_accuracy: 0.8270\n",
      "782/782 [==============================] - 115s 147ms/step - loss: 0.4221 - accuracy: 0.8234\n",
      "lstm Test Loss: 0.4221, LSTM Test Accuracy: 0.8234\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 128)         1280000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               99072     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1379201 (5.26 MB)\n",
      "Trainable params: 1379201 (5.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 192s 299ms/step - loss: 0.6543 - accuracy: 0.5910 - val_loss: 0.6552 - val_accuracy: 0.5704\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 187s 300ms/step - loss: 0.3860 - accuracy: 0.8203 - val_loss: 0.2914 - val_accuracy: 0.8770\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 189s 303ms/step - loss: 0.1839 - accuracy: 0.9320 - val_loss: 0.2823 - val_accuracy: 0.8878\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 209s 334ms/step - loss: 0.0965 - accuracy: 0.9676 - val_loss: 0.3489 - val_accuracy: 0.8774\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 188s 300ms/step - loss: 0.0546 - accuracy: 0.9827 - val_loss: 0.4473 - val_accuracy: 0.8616\n",
      "782/782 [==============================] - 103s 131ms/step - loss: 0.4221 - accuracy: 0.8234\n",
      "gru Test Loss: 0.4221, GRU Test Accuracy: 0.8234\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding , SimpleRNN, LSTM , Dense, GRU\n",
    "\n",
    "vocab_size = 10000\n",
    "max_len = 200\n",
    "\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words = vocab_size)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen = max_len, padding = \"post\" )\n",
    "X_test = pad_sequences(X_test, maxlen = max_len, padding = \"post\" )\n",
    "\n",
    "print(f\"train data shape{X_train.shape}\")\n",
    "print(f\"test data shape{X_test.shape}\")\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    Embedding(input_dim = vocab_size,output_dim = 128),\n",
    "    SimpleRNN(128, activation = \"tanh\", return_sequences = False),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "rnn_model.summary()\n",
    "\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs = 5, batch_size =5, validation_split = 0.2)\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X_test,y_test)\n",
    "\n",
    "print(f\"Rnn Test Loss: {rnn_loss:.4f}, Test Accuracy: {rnn_accuracy:.4f}\")\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim = vocab_size,output_dim = 128),\n",
    "    LSTM(128, activation = \"tanh\", return_sequences = False),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "\n",
    "lstm_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "lstm_model.summary()\n",
    "\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs = 5, batch_size =32, validation_split = 0.2)\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test,y_test)\n",
    "\n",
    "print(f\"lstm Test Loss: {lstm_loss:.4f}, LSTM Test Accuracy: {lstm_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "gru_model = Sequential([\n",
    "    Embedding(input_dim = vocab_size,output_dim = 128),\n",
    "    GRU(128, activation = \"tanh\", return_sequences = False),\n",
    "    Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "\n",
    "\n",
    "gru_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "gru_model.summary()\n",
    "\n",
    "gru_history = gru_model.fit(X_train, y_train, epochs = 5, batch_size =32, validation_split = 0.2)\n",
    "gru_loss, gru_accuracy = lstm_model.evaluate(X_test,y_test)\n",
    "\n",
    "print(f\"gru Test Loss: {gru_loss:.4f}, GRU Test Accuracy: {gru_accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f888f",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2379d16-d9e5-40b9-bb15-08fbebb29c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
